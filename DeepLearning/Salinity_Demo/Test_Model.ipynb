{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the test batches from files created by the Preprocessing_NN_Data notebook\n",
    "def read_batches(filepath):\n",
    "    batches = []\n",
    "    number_read = -1\n",
    "    while True:\n",
    "        number_read += 1\n",
    "        try:\n",
    "            batch = pd.read_csv(filepath + '_' + str(number_read) + '.csv', index_col=0, parse_dates=True)\n",
    "            batches.append(batch)\n",
    "        except FileNotFoundError:\n",
    "            break\n",
    "    return batches\n",
    "            \n",
    "test_batches = read_batches('data/test/batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert the dataframes in train_batches to the correct input and output shape (and make it arrays)\n",
    "def convert_to_keras_input(batches):\n",
    "    input_batches = []\n",
    "    output_batches = []\n",
    "    for batch in batches:\n",
    "        input_df = batch.iloc[:,1:]\n",
    "        output_df = batch['cl_kadij_out']\n",
    "        input_batches.append(input_df.as_matrix()[:,np.newaxis,:])\n",
    "        output_batches.append(output_df.as_matrix())\n",
    "    return (input_batches, output_batches)\n",
    "\n",
    "(input_test_batches, output_test_batches) = convert_to_keras_input(test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the trained model from a file\n",
    "model_filename = 'models/2layer_lstm_11cells'\n",
    "\n",
    "model = keras.models.load_model(model_filename + '.h5')\n",
    "info_file = open(model_filename + '_info.txt')\n",
    "info = ''\n",
    "for line in info_file:\n",
    "    info += line\n",
    "info_file.close()\n",
    "print('------- info of read model --------\\n')\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the test results:\n",
    "output_model = []\n",
    "actual_value = []\n",
    "basic_prediction = []\n",
    "output_model_last = []\n",
    "actual_value_last = []\n",
    "basic_prediction_last = []\n",
    "for i in range(0,len(test_batches)):\n",
    "    batch_output = model.predict(input_test_batches[i], batch_size = len(input_test_batches[i]))\n",
    "    batch_actual = output_test_batches[i]\n",
    "    for j in range(0, len(batch_output)):\n",
    "        output_model.append(batch_output[j].item())\n",
    "        actual_value.append(batch_actual[j].item())\n",
    "        basic_prediction.append((input_test_batches[i])[j,0,0])\n",
    "    output_model_last.append(batch_output[-1].item())\n",
    "    actual_value_last.append(batch_actual[-1].item())\n",
    "    basic_prediction_last.append((input_test_batches[i])[-1,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the scaler data from a file and define a function that retransforms the cl_kadij data to the actual values\n",
    "scaler_data = pd.read_csv('data/scaler_data.csv', index_col=0)\n",
    "\n",
    "def rescale_data(data,scaler_name):\n",
    "    data_range = scaler_data.loc[scaler_name, 'data_range_']\n",
    "    data_min = scaler_data.loc[scaler_name, 'data_min_']\n",
    "    converted = np.array(data) * data_range + data_min\n",
    "    return converted\n",
    "    \n",
    "def convert_cl_kadij_output(output):\n",
    "    rescaled_output = rescale_data(output, 'cl_kadij_scaler')\n",
    "    return np.exp(rescaled_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale and transform data back to original values:\n",
    "output_model_scaled = convert_cl_kadij_output(output_model)\n",
    "actual_value_scaled = convert_cl_kadij_output(actual_value)\n",
    "basic_prediction_scaled = convert_cl_kadij_output(basic_prediction)\n",
    "output_model_last_scaled = convert_cl_kadij_output(output_model_last)\n",
    "actual_value_last_scaled = convert_cl_kadij_output(actual_value_last)\n",
    "basic_prediction_last_scaled = convert_cl_kadij_output(basic_prediction_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define some functions to print analysis of test results\n",
    "def print_MSE(predicted, actual):\n",
    "    '''calculates the MSE and prints it, returns the MSE'''\n",
    "    errors = np.abs(predicted - actual)\n",
    "    squared_errors = errors**2\n",
    "    MSE = np.average(squared_errors)\n",
    "    print('MSE:', MSE)\n",
    "    return MSE\n",
    "\n",
    "def print_prediction_skill(predicted, actual, basic_predicted, verbose=False):\n",
    "    '''calculates the prediction skill compared to the basic prediction method of using the same value as yesterday\n",
    "       the calculated prediction skill is printed and returned\n",
    "       note that it calls the print_MSE function which will also print the MSE\n",
    "       use verbose=True to also print the MSE of the basic prediction method'''\n",
    "    MSE = print_MSE(predicted, actual)\n",
    "    basic_errors = np.abs(actual - basic_predicted)\n",
    "    basic_MSE = np.average(basic_errors**2)\n",
    "    prediction_skill = 1 - MSE / basic_MSE\n",
    "    if (verbose):\n",
    "        print('MSE basic method:', basic_MSE)\n",
    "    print('prediction skill:', prediction_skill)\n",
    "    return prediction_skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the analysis results for the test data\n",
    "print('When analysing prediction on all test data:')\n",
    "print_prediction_skill(output_model_scaled, actual_value_scaled, basic_prediction_scaled, True)\n",
    "print('When analysing prediction only on last value of each test batch:')\n",
    "print_prediction_skill(output_model_last_scaled, actual_value_last_scaled, basic_prediction_last_scaled, True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_index = 10\n",
    "print('batch size', len(test_batches[batch_index]))\n",
    "batch_output_model = model.predict(input_test_batches[batch_index], batch_size=len(input_test_batches[batch_index]))\n",
    "batch_output_actual_converted = convert_cl_kadij_output(output_test_batches[batch_index])\n",
    "batch_output_model_converted = convert_cl_kadij_output(batch_output_model)\n",
    "plt.plot(test_batches[batch_index].index.values, batch_output_actual_converted, 'b--', label='actual data')\n",
    "plt.plot(test_batches[batch_index].index.values, batch_output_model_converted, 'y', label='predicted data')\n",
    "plt.axhline(250, color='red')\n",
    "plt.legend();\n",
    "\n",
    "print('\\nWhen analysing each data point in this batch:')\n",
    "print_prediction_skill(batch_output_model_converted, batch_output_actual_converted, True);\n",
    "if (len(batch_output_actual_converted) >= 2):\n",
    "    print('\\nWhen analysing only the last data point in this batch:')\n",
    "    prediction_SE = ((batch_output_model_converted[-1] - batch_output_actual_converted[-1])**2)[0]\n",
    "    print('prediction SE:', prediction_SE)\n",
    "    basic_SE = (batch_output_actual_converted[-1] - batch_output_actual_converted[-2])**2\n",
    "    print('basic prediction SE:', basic_SE)\n",
    "    print('prediction skill based on this single point:', 1 - prediction_SE / basic_SE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the indices of big (>100) batches to use in the cell above\n",
    "batch_sizes = [len(batch) for batch in test_batches]\n",
    "print(np.where(np.array(batch_sizes) > 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
